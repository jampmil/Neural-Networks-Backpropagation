# Neural-Networks-Backpropagation

Implementation of a backpropagation algorithm for a configurable neural network.

Neural networks are mathematical models based on our own biological neural structures. Considering this, a neural network is composed by multiple neurons (or nodes), where each one of them takes multiple inputs and calculates a single output. In order to compute the output, all nodes use a weight, which will be multiplied by the input values. The neuron will combine these weighted inputs, together with an activation function, in order to determine its output, simulating in this way the basic operation of how real neurons work.

After researching different approaches to resolve the non-convex problem presented, two different solutions have been developed, in this case in Python, that can give a better understanding of how a Neural Network works and how can a problem of this nature be approached. It is also important to highlight that even though we have a proposed structure for the neural network, the solution developed was made to be configurable so it can receive different structures and find the optimal weights (please refer to Annex 1).
